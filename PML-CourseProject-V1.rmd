---
title: 'Practical Machine Learning: Course Project'
author: "Abheek Biswas"
output: html_document
fontsize: 10pt
---

## Project Introduction
### Background
Usage of fitness trackers viz. Jawbone Up, Nike FuelBand & Fitbit has now made it possible to collect a large amount of data pertaining to personal activity. Although people regularly quantify level of a particular activity done by them, they seldom quantify how they do it.

### Objective
In this project, our objective will be to use data from accelerometers on the belt, forearm, arm and dumbbell of 6 participants who have been asked to perform barbell lifts correctly and incorrectly in 5 different ways. Using this data, our aim is to predict the manner in this they did the exercise.

```{r message = FALSE, warning = FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
library(knitr)
```

## Getting and Loading Data
The training data for this project are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

```{r}
set.seed(1111)

trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

Partitioning the training set into myTraining and myTesting
```{r}
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
```

## Cleaning the data
Removing the NearZeroVariance variables

```{r}
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]

nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
```

Removing the first column of myTraining dataset and cleaning variables with more than 60% NA
```{r}
myTraining <- myTraining[c(-1)]

# Removing NA 
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
    if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
                trainingV3 <- trainingV3[ , -j]
            }   
        } 
    }
}

# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
```

Transform the myTesting and testing data sets
```{r}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining

dim(myTesting)
```

```{r}
dim(testing)
```

Coercing data into same type
```{r}
for (i in 1:length(testing) ) {
    for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}

# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
```

## Prediction with Data Trees
```{r}
set.seed(1111)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
rpart.plot(modFitA1)
```

```{r}
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
```

```{r}
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 4)))
```

## Prediction with Random Forest
```{r}
set.seed(1111)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
```

```{r}
plot(modFitB1)
```

```{r}
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
```

## Prediction with Generalized Boosted Regression
```{r}
set.seed(1111)
fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 1)

gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
                 trControl = fitControl,
                 verbose = FALSE)


gbmFinMod1 <- gbmFit1$finalModel

gbmPredTest <- predict(gbmFit1, newdata=myTesting)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, myTesting$classe)
gbmAccuracyTest
```

```{r}
plot(gbmFit1, ylim=c(0.9, 1))
```

## Cross Validation and Out of Sample Error Estimation
Random Forests gave an accuracy in the myTesting dataset of `r round(cmrf$overall['Accuracy'], 4)*100`%, which was more accurate than what we got from the other two methods: Decition Tree or Generalized Boosted Regression (GBM). The expected out of sample error is 100% - `r round(cmrf$overall['Accuracy'], 4)*100`% = `r 100 - round(cmrf$overall['Accuracy'], 4)*100`%.

## Predicting Results on Test Data
Thus the result of the way they performed the exercise is as given below
```{r}
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
```

